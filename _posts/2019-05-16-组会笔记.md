---
title: '5.16组会笔记'
date: 2019-05-16
permalink: /posts/2019/coai-group-dicussion-0516/
tags:
  - notes
---

### **Weak Supervision**

熵 -> uniform distribution
$$
-\sum^i_m q_i \, log \, d_i  ??
$$
Self-Training/Self-Supervised

Relieve Bias ?

EM optimization(similarity based loss + MIL/hinge loss/VAE)

Get higher-level supervision over unlabeled data from SMEs:

启发式规则

Distant Supervision, Constraints, Expected Distribution, Invariances.



### **External Knowledge**

#### Label-free EMNLP 2018

Based on TransE pretrianed embedding, start entity + sentence embedding(predicted relation vector from neural model) == end entity

